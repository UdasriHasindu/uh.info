{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb0a463",
   "metadata": {},
   "source": [
    "1. Load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f831b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"info.txt\")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079560c",
   "metadata": {},
   "source": [
    "2. Split into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26eb730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(document)\n",
    "\n",
    "print(len(all_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88047f",
   "metadata": {},
   "source": [
    "3. Create embedding (`Google gemini `)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec3eb595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "# vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "# assert len(vector_1) == len(vector_2)\n",
    "# print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "# print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3009abc",
   "metadata": {},
   "source": [
    "4. Vector store (`chromadb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65d99197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d48288f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "503eafa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['43a100a7-23ac-4a3f-86a4-cf8bd7e98937',\n",
       " '818f0b76-5576-4636-bf32-f7295db79cc0',\n",
       " '7e5e8baa-d65e-4c84-b665-87e3f1ac93e3',\n",
       " '27092b21-c208-4106-a6ca-bcd2373f56e7',\n",
       " '245ec5df-9c1e-464a-960b-3e85afa17553',\n",
       " '1ff0176d-e6f4-423d-a359-392d49f767c9',\n",
       " 'dad610b2-05f9-4b3d-b4ab-0cdacf426f25',\n",
       " '617321fb-3f06-4c68-b59d-f33497a31722',\n",
       " '6e7a9686-4afd-4936-9f2a-e0f0dc0aadab']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79787b",
   "metadata": {},
   "source": [
    "* Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "840abce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--------------------------------------------------\\n\\nEducation:\\n\\nBachelor of Science (Honours) in Computer Science\\nSpecialization: Artificial Intelligence\\nUniversity: University of Kelaniya\\nGPA: 3.7\\nDuration: 2023 – Present\\n\\nG.C.E. Advanced Level (2019 – 2021)\\nStream: Mathematics\\nResults: A, B, B\\n\\nG.C.E. Ordinary Level (2013 – 2018)\\nResults: 8 A passes and 1 B pass\\n\\n--------------------------------------------------\\n\\nTechnical Skills:'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"Education Qualifications\")\n",
    "\n",
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f017c",
   "metadata": {},
   "source": [
    "5. RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87314e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36d37f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " Hello! How can I help you with Udasri Hasindu's professional profile?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Create a prompt template\n",
    "template = \"\"\"You are an assistant answering questions about Udasri Hasindu's professional profile.\n",
    "Use the following pieces of context to answer the question. \n",
    "If you don't know the answer, just say that you don't know.\n",
    "Keep the answer concise and relevant.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Function to format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Create the RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Ask questions\n",
    "while True:\n",
    "    query = input(\"\\nAsk a question (or type 'exit'): \")\n",
    "    \n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    response = rag_chain.invoke(query)\n",
    "    print(\"\\nAnswer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886302d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
